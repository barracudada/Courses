{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Основное отличие DBSCAN и K-Means*: \n",
    "\n",
    "1.\tБлагодаря своей простой структуре K-Means обучается быстрее, чем DBSCAN\n",
    "2.\tDBSCAN  способен формировать кластеры любой формы, в то время как K-Means только определенной формы \n",
    "3.\tK-Means можно использовать для генерации новых признаков, а DBSCAN для этого неприменим\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Методу DBSCAN важно, чтобы точки находились плотно друг к другу, а их форма и расположение центра не особо важно.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В чем состоит сложность при работе с DBSCAN*: \n",
    "\n",
    "1.\tСложен в обучении\n",
    "2.\tНеобходимо делать предположения о следующих двух параметрах: размер окрестности и количество соседей.\n",
    "3.\tНе учитывает, что в данных могут быть выбросы\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** По построению DBSCAN, в дейтсвительно, предполагает некоторые априорные представления об этих двух параметрах\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Какая задача напрямую не решается кластеризацией?*: \n",
    "\n",
    "1.\tПоиск похожих клиентов для рекомендательных систем\n",
    "2.\tПредсказание ВВП по заголовкам новостных источников \n",
    "3.\tВыделение групп похожих ответов в соц. опросах\n",
    "4.\tОбъединение сообществ в соц. сетях по тематикам\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Предсказание ВВП - это задача обучения с учителем. Конечно, решая ее, можно использовать алгоритмы кластеризации, скажем, для создания новых категориальных признаков. Но напрямую кластеризировать ВВП не получится :)\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача - предсказать есть диабет у индивида или нет. В качестве таргета - колонка Diabetes. В нем три различных значения: `0`, `1`, `2`. `0` означает, что наблюдаемой здоров, `1` значит, что есть риск диабета, `2` означает наличие диабета. В качестве признаков будем использовать пол, количество лет в США, доход семьи и некоторые показатели, измеренные медицинскими работниками.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** В этой части ДЗ попробуем использовать кластеризацию как инструмент при проведении моделирования в задаче классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Загрузим датасет\n",
    "\n",
    "df = pd.read_csv('datahw21.csv', index_col='Unnamed: 0')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Посмотрим как устроены данные\n",
    "### Изобразим корреляционную матрицу\n",
    "\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн-тест\n",
    "\n",
    "data = df.drop(['Diabetes'], axis=1)\n",
    "target = df[['Diabetes']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    target, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы использовать K-means, лучше будет отнормировать данные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Воспользуемся StandardScaler\n",
    "\n",
    "cols = X_train.columns\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=cols)\n",
    "X_test_sc = pd.DataFrame(scaler.transform(X_test), columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим K-Means с параметрами `n_clusters` = 3, `tol` = 0.0005. Выбор параметров обусловлен тем, что у нас три возможных значения таргета. Но в целом основной подход подбора количества кластеров - по кривой зависимости внутрикластерного и межкластерного расстояний от количества кластеров.\n",
    "\n",
    "Установите `random_state` = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms = KMeans(n_clusters = 3, \n",
    "             tol = 0.0005,\n",
    "             random_state=1)\n",
    "\n",
    "kms.fit_predict(X_train_sc)\n",
    "\n",
    "print (\"parameters: \", kms.get_params)\n",
    "print (\"preict: \", kms.predict)\n",
    "print (\"\\nscore: %.2f\" % kms.score(X_test_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем качество на изначальных данных(нормированных). Для этого обучите с дефолтными параметрами `RandomForestClassifier`, `LogisticRegression`, `LinearSVC`. Там, где нужно, установите `random_state` = 1. (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "\n",
    "rf.fit(X_train_sc, y_train)\n",
    "lr.fit(X_train_sc, y_train)\n",
    "svm.fit(X_train_sc, y_train)\n",
    "\n",
    "print('RF acc:', accuracy_score(y_test, rf.predict(X_test_sc)))\n",
    "print('LR acc:',accuracy_score(y_test, lr.predict(X_test_sc)))\n",
    "print('SVM acc:',accuracy_score(y_test, svm.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в признаковое описание номер кластера и посчитайте качество с новым признаком! Стало ли качество хоть сколько-то лучше? (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k = pd.concat(\n",
    "    [\n",
    "        X_train_sc,\n",
    "        pd.DataFrame(kms.predict(X_train_sc), columns=['Cluster_num'])   # <-- добавляем кластер как признак\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "X_test_k = pd.concat(\n",
    "    [X_test_sc,\n",
    "     pd.DataFrame(kms.predict(X_test_sc), columns=['Cluster_num'])       # <-- добавляем кластер как признак\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "\n",
    "rf.fit(X_train_k, y_train)\n",
    "lr.fit(X_train_k, y_train)\n",
    "svm.fit(X_train_k, y_train)\n",
    "\n",
    "print('RF acc:', accuracy_score(y_test, rf.predict(X_test_k)))\n",
    "print('LR acc:',accuracy_score(y_test, lr.predict(X_test_k)))\n",
    "print('SVM acc:',accuracy_score(y_test, svm.predict(X_test_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем расстояния от объектов до центров кластеров. Для этого воспользуемся методом `transform` обученного класса kmeans.\n",
    "\n",
    "Обучим и посчитаем метрики исключительно на расстояниях до центра. Убедимся, что такой подход имеет право на существование, если данные позволяют, то качество не сильно должно пострадать. А в каких-то случаях может оказаться даже лучше! Таким образом можно снижать размерность данных. (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1 = kms.transform(X_train_sc)            #  <--- расстояния от объектов до центра кластеров на трейне\n",
    "new2 = kms.transform(X_test_sc)             #  <--- расстояния от объектов до центра кластеров на трейне\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "\n",
    "rf.fit(new1, y_train)\n",
    "lr.fit(new1, y_train)\n",
    "svm.fit(new1, y_train)\n",
    "\n",
    "print('RF acc:', accuracy_score(y_test, rf.predict(new2)))\n",
    "print('LR acc:',accuracy_score(y_test, lr.predict(new2)))\n",
    "print('SVM acc:',accuracy_score(y_test, svm.predict(new2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (Бонус)** Задача кластеризации может использоваться не только для специфических задач группировки данных, но и для оптимизации других методов. Вы уже знаете, что одна из основных проблем kNN в скорости его предсказания. В этом задании попробуем ускорить работу kNN с помощью кластеризации, не теряя при этом сильно в качестве.\n",
    "\n",
    "Сначала загрузим уже известные вам данные клиентов страховой компании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Загрузим известный нам датасет\n",
    "\n",
    "data = pd.read_csv('processed_vehicle_inssurance.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн-тест\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('Response', axis=1)[:25000]\n",
    "y = data['Response'][:25000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values,\n",
    "                                                    random_state=0,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Нормируем данные\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите обычный kNN с одним соседом и измерьте качество, например, взвешенную f-меру, чтобы потом сранить с нашей реализацией. (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, roc_curve, auc\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея ускорения kNN заключается в том, чтобы разбить признаковое пространство (то есть столбцы, а не объекты-строки!) на несколько блоков и кластеризовать каждый блок по-отдельности.\n",
    "\n",
    "Далее нужно будет заменить в обучающей выборке объекты на их некоторое представление, а именно вместо каждого блока вставить центр кластера, к которому принадлежит эта часть исходного объекта.\n",
    "\n",
    "Затем подсчет расстояний на этапе применения производится по блокам. Главный плюс алгоритма в том, что у нас уже будут иметься предподсчитанные расстояния по блокам до всех центров кластеров.\n",
    "\n",
    "Этот алгоритм называется **Product Quantization**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам алгоритм:\n",
    "\n",
    "1. Разделите обучающую и контрольную выборки на блоки: равномерно по индексам столбцов.\n",
    "\n",
    "\n",
    "2. На каждом блоке обучите K-Means и примените transform к соотв. блоку контрольной выборки.\n",
    "\n",
    "\n",
    "3. Посчитайте расстояния от каждого обучающего объекта до каждого объекта из контрольной выборки\n",
    "(это вы должны сделать, используя матрицы из предыдущего пункта)\n",
    "\n",
    "\n",
    "4. Определите для каждого тестового объекта k ближайших"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей реализации будем использовать следующие значения параметров: \\\n",
    "`m_blocks` = 5 \\\n",
    "`n_clusters` = 100 \\\n",
    "`k` = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_quantization(X_train, X_test, m_blocks=5, n_clusters=100):\n",
    "    dist_table = np.zeros([X_test.shape[0], n_clusters, m_blocks])\n",
    "    X_train_clusters = np.zeros([X_train.shape[0], m_blocks])\n",
    "    \n",
    "    for i in range(m_blocks):\n",
    "        ### Вырежьте блок из обучающей и контрольной выборок\n",
    "        block_size = X_test.shape[1] // m_blocks\n",
    "        X_train_block = X_train[:, i*block_size:(i+1)*block_size].copy()\n",
    "        X_test_block = X_test[:, i*block_size:(i+1)*block_size].copy()\n",
    "        \n",
    "        ### Обучите K-Means и примените transform на тестовой выборке\n",
    "        ### Положите посчитанные расстояния до центров в матрицу dist_table\n",
    "        kmeans = KMeans(n_clusters=n_clusters).fit(X_train_block)\n",
    "        dist_table[:, :, i] = kmeans.transform(X_test_block)\n",
    "        \n",
    "        ### Положите метки кластеров в матрицу X_train_clusters\n",
    "        X_train_clusters[:, i] = kmeans.predict(X_train_block)\n",
    "        \n",
    "    return X_train_clusters, dist_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Совет на будущее в практике:** Обучайте все на подвыборке данных, так как итоговая матрица при подсчете kNN будет занимать очень много оперативной памяти. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_clusters, dist_table = product_quantization(X_train, X_test, \n",
    "                                                    m_blocks=5, \n",
    "                                                    n_clusters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с помощью полученных таблиц осталось посчитать расстояния до каждого объекта обучающей выборки. \n",
    "1. Сначала возведите в квадрат `dist_table`, чтобы получить сумму квадратов, а не l2-норму.\n",
    "\n",
    "2. Для каждого блока по предсказанным меткам класса в `X_train_clusters` отберите соответсвтующие расстояния из dist_table\n",
    "\n",
    "3. Просуммируйте квадраты расстояний по всем блокам.\n",
    "\n",
    "4. Найдите индексы самых маленький расстояний и по ним выберите объекты из y_train, это и будут наши предсказания\n",
    "\n",
    "Замерьте качество, как изменилась скорость работы? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sumsq_table = dist_table ** 2\n",
    "sumsq_table.shape\n",
    "\n",
    "X_train_clusters = X_train_clusters.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distances = np.zeros([sumsq_table.shape[0], X_train.shape[0]])\n",
    "m_blocks = 5\n",
    "\n",
    "for b in range(m_blocks):\n",
    "    distances += sumsq_table[:, X_train_clusters[:, b], b]\n",
    "\n",
    "y_pred = y_train[np.argmin(distances, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша реализация на python работает медленнее по сравнению с библиотечным kNN. Однако реализация на более низкоуровневых языках программирования (C++) и на большом количестве данных данный метод на самом деле позволяет ускорять подсчет расстояний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
