{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим датасет с машинами. Цель - верно восстанавливать для каждой из них цену продажи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('autos.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Колонка с тергетом - \"selling price\"\n",
    "\n",
    "X = data.drop(\"selling_price\", axis=1)\n",
    "y = data[\"selling_price\"]\n",
    "\n",
    "### Будем замерять MSLE!\n",
    "### Поэтому прологарифмируем таргет\n",
    "### А после оптимизируем MSE\n",
    "\n",
    "y = y.apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн и тест!\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание__ \n",
    "\n",
    "Реализуйте свой MeanTargetEncoder с добавленем некоторого шума!\n",
    "\n",
    "Однажды в лекционном материале, обсуждая счетчики, мы говорили с вами о том, что из-за них модели могут переобучаться. Один из способов бороться с этим - валидировать расчеты среднего таргета (стратегия отложенной выборки / расчеты на кросс-валидации). Но есть еще проще!\n",
    "\n",
    "Можно просто к значению счетчика добавить случайный шум (зашумить данные)!\n",
    "\n",
    "Напомним, что рассчитываться новые признаки должны по такой формуле:\n",
    "\n",
    "$$\n",
    "g_j = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}{l} + C * \\epsilon\n",
    "$$\n",
    "\n",
    "\n",
    "Пусть шум будет случайной величиной из нормального стандартного распределения, то есть $\\epsilon \\sim N(0, 1) $, а $ C = 0.006$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создавай свой класс-трансформер, наследуйтесь от классов `BaseEstimator, TransformerMixin` из `sklearn.base`. Трансформер не должен модифицировать передаваемую ему выборку inplace, а все необходимые статистики нужно считать только по обучающей выборке в методе `fit`. \n",
    "Ваш трансформер должен принимать при инициализации список из категориальных признаков и список из числовых признаков. \n",
    "\n",
    "Если для какого-то признака в тестовой выборке отсутствует значение, трансформер должен поставить там 0.\n",
    "\n",
    "На выходе должен получиться датасет того же размера с измененными категориальными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = ['name', 'year', 'fuel', 'seller_type', 'transmission', 'owner']\n",
    "num_cols = ['km_driven']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MeanTargetEncoderNoise(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categorical, numeric):\n",
    "        \n",
    "        ### Your code is here\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        ### Your code is here\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \n",
    "        ### Your code is here\n",
    "        \n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Проверка работы трансформера\n",
    "\n",
    "np.random.seed(1)\n",
    "transformer = MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)\n",
    "\n",
    "transformer.fit(X_train, y_train)\n",
    "\n",
    "train = transformer.transform(X_train)\n",
    "test = transformer.transform(X_test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите несколько деревьев, перебирая максимальную глубину алгоритма из списка `max_depth_list`, а остальные параметры оставьте дефолтными. Выведите лучшее значение гиперпараметра. Постройте график зависимости MSLE на тестовой выборке от значения гиперпараметра. Воспользуйтесь `Pipeline` без `GridSearch`. Проделайте то же самое с `min_samples_split`, `min_impurity_decrease`, `max_leaf_nodes`. (по 2б на каждый параметр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = [3, 5, 8, 12]\n",
    "min_samples_split_list = [10, 50, 100, 500]\n",
    "min_impurity_decrease_list = [0, 0.1, 0.15, 0.2]\n",
    "max_leaf_nodes_list = [100, 200, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите лучшую комбинацию параметров, используя `GridSearchCV` и набор массивов значений параметров из предыдущего задания. Для лучшей комбинации посчитайте MSLE на тестовой выборке. Получились ли лучшие параметры такими же, как если бы вы подбирали их по-отдельности при остальных гиперпараметрах по умолчанию (предыдущее задание)? (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"decision_tree__max_depth\": [3, 5, 8, 12],\n",
    "    \"decision_tree__min_samples_split\": [10, 50, 100, 500],\n",
    "    \"decision_tree__min_impurity_decrease\": [0, 0.1, 0.15, 0.2],\n",
    "    \"decision_tree__max_leaf_nodes\": [100, 200, 500]\n",
    "}\n",
    "np.random.seed(1)\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
