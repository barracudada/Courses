{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5823bd",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c6c01",
   "metadata": {},
   "source": [
    "*Допустим в задаче fraud detection (бинарной классификации) среди 100 объектов положительного класса модель правильно предсказала 60, а среди 9900 объектов отрицательного класса правильно предсказала 9000. Как можно корректно оценить качество именно этой модели?*: \n",
    "\n",
    "1.\tПосчитав долю верно предсказанных классов accuracy = (9000 + 60) / 10000 = 0.906, так как такую метрику легко интерпретировать как «точность» предсказаний нашей модели. \n",
    "2.\tИз полученной матрицы ошибок можно посчитать precision и recall и, перебирая всевозможные пороги для вероятностей, получить желаемое значение в зависимости от поставленной бизнес-задачи. \n",
    "3.\tПосчитать площадь под графиком ROC с помощью перебора всех порогов для предсказанных вероятностей в точке TPR =  60/100 = 0.6 и FPR = 900/9900 = 0.09.\n",
    "4.\tВ нашей задаче важен именно положительный класс, поэтому стоит использовать F-меру, используя подсчитанный Precision = 60/(60+900) = 0.0625 и Recall = 60/100 = 0.6.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 4)** при несбалансированных выборках accuracy не подойдет, так как мы хотим больше уделять внимание положительному классу. Здесь требуется оценить качество модели при заданном пороге, поэтому перебирать пороги не требуется, хотя если нужно выбрать порог, то ROC AUC более чувствителен к дисбалансу классов и лучше использовать PR AUC.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07008c99",
   "metadata": {},
   "source": [
    "*В каких случаях используют регуляризацию и какую норму выбирать для неё?*: \n",
    "\n",
    "1.\tРегуляризация помогает частично решить проблему строгой мультиколлинеарности признаков, что ведет к вырожденности ковариационной матрицы.\n",
    "2.\tРегуляризация может помочь в отборе информативных признаков, если использовать квадрат l2-нормы для весов, которая с больше вероятностью зануляет веса, чем l1-норма.\n",
    "3.\tРегуляризация решает проблему больших весов в линейных моделях из-за высокой коррелированности признаков, используя l2-норму можно ограничить веса и получить более качественную модель.\n",
    "4.\tРегуляризация используется для предотвращения переобучения модели, она понижает обобщающую способность модели взамен на большее качество на обучающей выборке.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 3)** строгая мультиколлинеарность решается удалением линейно зависимого признака (обычно такое происходит при dummy trap). Зануляет веса l1-регуляризация с помощью которой можно отбирать важные признаки. Регуляризация наоборот повышает обобщающую способность модели, частично предотвращая переобучение.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c538d2",
   "metadata": {},
   "source": [
    "*Сколько моделей надо обучить и сколько в них обучаемых параметров, если мы обучаем Ridge регрессию на 20 признаках, среди которых нет константного с помощью 8-Fold кросс валидации?*: \n",
    "\n",
    "1.\tНадо обучить 8 моделей, где в каждой 20 обучаемых параметров. \n",
    "2.\tНадо обучить 9 моделей, где в каждой 20 обучаемых параметров.\n",
    "3.\tНадо обучить 8 моделей, где в каждой 22 обучаемых параметров.\n",
    "4.\tНадо обучить 9 моделей, где в каждой 22 обучаемых параметров.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 1)** параметр регуляризации не обучается, поэтому обучаемых параметров 20 + 1 константа. В кросс-валидации на каждом фолде валидируется одна модель, а на всех остальных обучается.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729626b8",
   "metadata": {},
   "source": [
    "*Почему в градиентном спуске мы делаем шаги в сторону антиградиента при обучении весов?*: \n",
    "\n",
    "1.\tТак как мы ищем максимум функционала, а антиградиент показывает направление его наискорейшего роста. \n",
    "2.\tТак как мы ищем максимум функционала, а антиградиент показывает направление, в котором находится его глобальный минимум. \n",
    "3.\tТак как мы ищем минимум функционала, а антиградиент показывает направление его наискорейшего убывания. \n",
    "4.\tТак как мы ищем минимум функционала, а антиградиент показывает направление, в котором находится его глобальный минимум. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 3)** направление наискорейшего убывания в том числе может показывать на локальный минимум, в этом и проблема градиентного спуска, которая может решаться, например, с помощью multistart или алгоритмами оптимизации, устойчивыми к застреванию в глобальном минимуме (simulated annealing, спуск с инерцией). \n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41c837",
   "metadata": {},
   "source": [
    "*Выберете верное утверждение про изменение точности и полноты при подборе порога на отсортированных по возрастанию предсказанных вероятностях*: \n",
    "\n",
    "1. При увеличении порога и precision, и recall растут\n",
    "2. При увеличении порога растет исключительно recall\n",
    "3. При увеличении порога precision может как расти, так и падать, а recall растет\n",
    "4. При увеличении порога precision растет, а recall падает\n",
    "5. При увеличении порога precision может как расти, так и падать, а recall падает\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 5)** Пусть есть положительный и отрицательный класс (+1 и -1). Пусть наша модель отсортировала вероятности от наибольшего к наименьшему так, что истинные метки на всей выборке, состоящей из 3 объектов, оказались равны (отсортированные): +1 -1 +1. Есть 4 опции установить порог:\n",
    "\n",
    "         I опция:   II опция:    III опция:    IV опция: \n",
    "\n",
    "         +1             +1              +1             __\n",
    "\n",
    "         -1             -1              __             +1\n",
    "         \n",
    "         +1             __              -1             -1\n",
    "         \n",
    "         __             +1              +1             -1\n",
    "\n",
    "Все, что выше выбранного порога (__) относится к положительному классу!\n",
    "\n",
    "Посчитайте для каждой опции как precision, так и recall! :)\n",
    "\n",
    "Recall будет меняться всегда в одну сторону, а precision нет.\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dee67f",
   "metadata": {},
   "source": [
    "*Пусть наш классификатор должен корректно оценивать вероятности покупки товара на сайте, чтобы компания могла правильно оценить будущую выручку, какую модель лучше НЕ использовать для этой задачи?*: \n",
    "\n",
    "1.\tSVM, так как он максимизирует отступ между классами, тем самым сильнее изгибая калибровочную кривую. \n",
    "2.\tЛогистическая регрессия, так как стандартная логистическая функция не может описывать любое распределение вероятностей.\n",
    "3.\tkNN, так как в нем учитываются только расстояния между объектами, не оценивающие никакие вероятности.\n",
    "4.\t Изотоническая регрессия на выходах логистической регрессии, так как она минимизирует квадрат отклонения ответов от меток\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 1)** SVM действительно хуже всех оценивает вероятности, зато лучше максимизирует уверенность своих предсказаний, а не вероятностей, такое свойство полезно для задач четкого разграничения между классами, например классификации спам-писем. \n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd34c6",
   "metadata": {},
   "source": [
    "*Пусть Вы решаете задачу регрессии. Допустим, у всех объектов обучающей выборки целевые переменные положительные. Могут ли быть отрицательные прогнозы у решающего дерева, обученного на этой выборке (если оно обучается на MSE)? А у отдельных деревьев в составе случайного леса? А у отдельных деревьев в составе градиентного бустинга?*: \n",
    "\n",
    "\n",
    "1.\tДеревья в составе всех трёх алгоритмов не могут выдавать неположительные прогнозы, так как у всех объектов положительные целевые переменные\n",
    "2.\tРешающее дерево не может выдавать в таком случае неположительные ответы, но в то же время отдельные деревья в составе градиентного бустинга и случайного леса могут выдавать прогнозы любого знака.\n",
    "3.\tРешающее дерево не может выдавать в таком случае неположительные ответы, отдельные деревья в составе леса тоже. А вот отдельные деревья в градиентном бустинге могут выдавать прогнозы любого знака. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 3)** дерево не может, так как в каждом листе выдается среднее целевых переменных для объектов в этом листе. Для леса объяснение такое же, там так же строятся деревья. Выборка будет другой, в каждом листе случайное подмножество признаков, но таргеты у объектов будут положительными все равно. Деревья в бустинге строятся, чтобы приблизить производные функции потерь в точке равной прогнозу уже построенного ансамбля, соответственно знак прогноза может быть любым. \n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ac557",
   "metadata": {},
   "source": [
    "*В случаях, когда категориальные признаки имеют слишком большое количество уникальных значений, применять OHE нецелесообразно. На помощь приходят LabelEncoder(LE) и MeanTarget(MTE). С какими проблемами Вы можете столкнуться при их использовании?*: \n",
    "\n",
    "\n",
    "1.\tПри использовании LE легко переобучиться. Также существует проблема обработки новых категорий на контрольной выборке, такая проблема встречается и у MTE.\n",
    "2.\tОба этих способа кодирования категориальных признаков ведут к переобучению, в особенности MTE. Также у MTE есть проблема с обработкой новых категорий.\n",
    "3.\tLE задаёт порядок на категориях, который лишь зашумляет данные. Использование МТЕ ведет к переобучению. Проблема с обработкой новых категорий встречается у обоих способов. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 3)** с LE действительно тяжело работать во многих случаях из-за порядка на категориях, который никак не обоснован и мешает обучаться, например, линейным моделям. Использования средних значений таргетов в МТЕ ведет к переобучению, поэтому придумали разные модификации этого метода. Оба метода не подразумевают, что могут встретиться новые категории.\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5d2fc",
   "metadata": {},
   "source": [
    "*Что из перечисленного ниже приведёт к понижению смещения решающего дерева, а что к повышению?*: \n",
    "\n",
    "\n",
    "А) увеличение максимально допустимой глубины дерева до определенного значения \n",
    "\n",
    "Б) обучение дерева на случайном подмножестве признаков (вместо обучения на всех признаках) \n",
    "\n",
    "В) замена поиска оптимального предиката в каждой вершине на выбор случайного предиката\n",
    "\n",
    "1.\tПовышение: Б, А; понижение: В\n",
    "2.\tПовышение: В, А; понижение: Б\n",
    "3.\tПовышение: Б; понижение: А, В\n",
    "4.\tПовышение: Б, В; понижение: А\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 4)** Пояснения:\n",
    "\n",
    "A) Чем глубже дерево, тем сложнее зависимости модель будет способна оценивать, а значит, вероятно, будет ближе всего к идеальной модели (но зато будет переобучаться). \n",
    "\n",
    "Б) Бустрап, в действительности, может немного \"скосить\" истинную зависимость, так как мы обучаем модель не на оригинальном датасете, а лишь на его некотором подмножестве. \n",
    "\n",
    "В) Выбирая случайный предикат в вершинах, мы, соответственно, получим какую-то совершенно случайную модель, которая вряд ли будет попадать в идеальную зависимость.\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc86d3",
   "metadata": {},
   "source": [
    "*Пусть Вы решаете задачу бинарной классификации. Будем обучать на такую функцию потерь. Какие минусы вы видите в этом подходе?*: \n",
    "\n",
    "\n",
    "$$\n",
    "\\cfrac{1}{l} \\sum_{i=1}^l (y_i \\langle \\omega, x_i \\rangle - 1)^2\n",
    "$$\n",
    "\n",
    "1.\tНорма весов будет слишком большой, что может привести к переобучению \n",
    "2.\tНе получится достичь нулевой ошибки на обучающей выборке\n",
    "3.\tМы будем штрафовать за отклонения отступа в большую от единицы сторону\n",
    "4.\tМодель будет выдавать константный прогноз на всех объектах\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 3)** из-за того, что мы будем штрафовать за отклонения в большую сторону, может получиться так, что модели выгодно будет ошибаться на некоторых объектах, чтобы уменьшить отступ на объектах, у которых от должен был быть большим. Обучаясь таким образом, мы не получим хорошее качество классификации\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98170ba4",
   "metadata": {},
   "source": [
    "*Пусть мы обучаем градиентный бустинг. Очередную базовую модель мы обучаем на отклонения от производной лосса в точке равной прогнозу уже построенного ансамбля. Вопрос: почему это лучше, чем обучаться на отклонения прогноза уже построенного ансамбля от правильного ответа?*: \n",
    "\n",
    "\n",
    "\n",
    "1.\tТак как таким образом обучение происходит быстрее\n",
    "2.\tВ таком случае мы учитываем особенности задачи, которые воплощены в лоссе. При этом мы не переобучаемся под данные на обучающей выборке\n",
    "3.\tНа отклонения от правильного ответа невозможно обучиться, так как в бустинге базовые модели берутся слишком слабыми по-отдельности. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** пояснение, по сути, сформулировано в самом варианте ответа.\n",
    "___________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
