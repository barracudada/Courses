{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Июльский курс (2020) PRO. Домашнее задание 26. Pytorch .Часть #2. Шаблон ноутбука",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D2Vsc8Dp_Rg"
      },
      "source": [
        "from torchvision import models # здесь лежат предобученные сетки\n",
        "\n",
        "import argparse\n",
        "from types import SimpleNamespace # простой класс, где можно прописать параметры\n",
        "import json\n",
        "\n",
        "# Для визуализации\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import scipy\n",
        "\n",
        "# Библиотеки Pytorch\n",
        "import torch \n",
        "import torchvision # здесь лежит mnist, cifar и много других датасетов и трансформаций для картинок\n",
        "import torch.nn as nn # здесь лежат все слои\n",
        "import torch.utils.data as data # работа с загрузчиком данных\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets #работа с классом Датасет\n",
        "from torch.autograd import Variable # для автоматического дифференциатора"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNWndvFjAod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "462904b1-0549-41c7-90e5-d4e7ddb21faf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghyc5xCgbV2M"
      },
      "source": [
        "## Пример использования предобученной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvav-H9dbV2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "778370f0-47d8-416b-e413-62672f98224c"
      },
      "source": [
        " # загружаем готовую предобученную сеть, переключаем в режим проверки"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 161MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3wrHbDlbV2O"
      },
      "source": [
        "Загружаем разметку между названием класса и соответствующему ему числу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "e4mzyJhCbV2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "6664ce35-ce3c-4ee6-9203-23f5bf9c2c40"
      },
      "source": [
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json # подгружаем одной командой (из документации ImageNet)\n",
        "class_idx = json.load(open(\"imagenet_class_index.json\"))\n",
        "idx2label = np.array([class_idx[str(k)][1] for k in range(len(class_idx))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-17 13:37:58--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.38.142\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.38.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [application/octet-stream]\n",
            "Saving to: ‘imagenet_class_index.json’\n",
            "\n",
            "imagenet_class_inde 100%[===================>]  34.53K   191KB/s    in 0.2s    \n",
            "\n",
            "2019-11-17 13:37:59 (191 KB/s) - ‘imagenet_class_index.json’ saved [35363/35363]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJS4_i4rbV2V"
      },
      "source": [
        "vgg16 была обучена на датасете imagenet, где входящие значения были нормализованы следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWNrEdXbV2W"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
        "                                                                            std=(0.229, 0.224, 0.225))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7mTsMkB7UH5"
      },
      "source": [
        "Посмотрим, что умеет эта сетка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUqF11HybV2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "e1ac2b12-7a4c-40ea-dc36-dfcbcc3a0658"
      },
      "source": [
        "# Загружаем картинку\n",
        "\n",
        "# Применяем нормализацию\n",
        "\n",
        "\n",
        "#Пропустим через софтмакс выход с последнего слоя предобученной сети, через которую мы прогнали наше изображение\n",
        "                                                       # добавляем дополнительное измерение,\n",
        "                                                       # чтобы получить тензор формата [размер batch, ширина, высота, количество каналов]\n",
        "                                                       # и вытягиваем в вектор\n",
        "                                                       \n",
        "sortedOuputs = torch.argsort(probas, descending=True) # в соответствие с каждой вероятностью подбираем класс\n",
        "\n",
        "# Вывод 5 наиболее вероятных классов\n",
        "for i in range(5):\n",
        "    print(\"Метка класса: {:s} - Вероятность: {:4f}\".format(\n",
        "        idx2label[sortedOuputs[i]], probas[sortedOuputs[i]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 300, 300])\n",
            "Метка класса: lorikeet - Вероятность: 0.505242\n",
            "Метка класса: bee_eater - Вероятность: 0.186730\n",
            "Метка класса: macaw - Вероятность: 0.113632\n",
            "Метка класса: toucan - Вероятность: 0.033876\n",
            "Метка класса: fig - Вероятность: 0.015141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiJrHjnXbV2e"
      },
      "source": [
        "## Настройка (Fine-tuning) предобученной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3JN7Yo_bV26"
      },
      "source": [
        "Загрузим выбранный датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWnd7f51bV28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4751ded8-8db3-46f5-e7f2-ac3c57355479"
      },
      "source": [
        "batchSize = ?\n",
        "numClasses = ?\n",
        "numEpochs = ?\n",
        "learningRate = ?\n",
        "\n",
        "trainDataset = \n",
        "\n",
        "testDataset = \n",
        "\n",
        "trainLoader = \n",
        "\n",
        "testLoader = "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oziSlIq_7Cdk"
      },
      "source": [
        "iterator = iter(trainLoader)    \n",
        "samples, labels = iterator.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsQUah5V7FD7"
      },
      "source": [
        "# Узнаем, с каким размером мы работаем, чтоб ввести правильные параметры слоя\n",
        "print(?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llunO94FbV3D"
      },
      "source": [
        "# Заменим последний слой для настройки под наш датасет\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpxe_w9WbV3J"
      },
      "source": [
        "# Функция ошибки\n",
        "# Оптимизатор\n",
        "\n",
        "# Обучим наш последний слой\n",
        "\n",
        "# Сохраним полученные веса\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPaVaYfxkyFG"
      },
      "source": [
        "# включаем режим проверки\n",
        "\n",
        "# проверим результат сети"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbUO_JuAmhMF"
      },
      "source": [
        "# посмотрите на размер картинки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5eWQWaSlDKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "cd7b97a3-36d2-4c1b-e013-505b57b98aa9"
      },
      "source": [
        "im = images[5,1].numpy() # Превращаем первую картинку в массив\n",
        "im = 255*np.reshape(im,(?,?)) # Приводим к формату RGB\n",
        "x = Image.fromarray(im.astype(np.uint8)).convert('RGBA') #Данные массива должны быть универсальной кодировки и приводим к формату изображения\n",
        "\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "\n",
        "# Предсказание\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAp2IRJBwS5EIijYhUiE/wdg9+5oeSOHhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Предсказание: лягушка\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs1ib6_oywFi"
      },
      "source": [
        "# Generative Adversive Network\n",
        "На базе предложенного алгоритма [A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf)\n",
        "\n",
        "[Здесь](https://poloclub.github.io/ganlab/) вы можете ознакомиться с работой GAN наглядно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACnM-yXNp_Rp"
      },
      "source": [
        "config = SimpleNamespace() # Создаем базовый класс пространства имен\n",
        "config.content = '/content/drive/My Drive/Занятия/Майский курс/Занятие #24-25. Pytorch. Часть #1,2/example/Indian-Ring-Necked-Parakeet-300x300.jpg' # наша основная картинка\n",
        "config.style = '/content/drive/My Drive/Занятия/Майский курс/Занятие #24-25. Pytorch. Часть #1,2/thumb-1920-247154.jpg' # наша стилизованная картинка\n",
        "config.maxSize = 400 # максимально допустимый размер изображения\n",
        "config.totalStep = 2000 # общее количество шагов за эпоху\n",
        "config.step = 10 # шаг\n",
        "config.sampleStep = 200 # шаг для сохранения образца\n",
        "config.styleWeight = 100 #вес на стиль\n",
        "config.lr = .003 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24y6AHjzp_Rt"
      },
      "source": [
        "# Проверка, если GPU включен\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW3nMsEWp_Ry"
      },
      "source": [
        "class PretrainedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Инициализируем нашу модель\n",
        "        super(PretrainedNet, self).__init__()\n",
        "        self.select = [0, 5, 7, 23, 9] # те слои, через которые мы будем пропускать свое изображение\n",
        "        self.pretrainedNet = models.vgg19(pretrained=True).to(device) # подгружаем предобученную сетку\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = [] # Извлекаем по индексам, которые мы прописали выше, feature map из сетки\n",
        "        output = x\n",
        "        for layerIndex in range(len(self.pretrainedNet.features)):\n",
        "          output = self.pretrainedNet.features[layerIndex](output)\n",
        "          if layerIndex in self.select:\n",
        "            features.append(output)\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxaqKeDDp_R4"
      },
      "source": [
        "def load_image(image_path, transform=None, maxSize=None, shape=None):\n",
        "    # Загружаем изображение\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Если указан максимальный размер, то меняем размер нашего изображения\n",
        "    if maxSize:\n",
        "        scale = maxSize / max(image.size)\n",
        "        size = np.array(image.size) * scale\n",
        "        image = image.resize(size.astype(int), Image.ANTIALIAS)\n",
        "        \n",
        "    # Если указана форма изображением, меняем форму\n",
        "    if shape:\n",
        "        image = image.resize(shape, Image.LANCZOS)\n",
        "\n",
        "    # Если указаны методы трансформирования, то применяем его\n",
        "    if transform:\n",
        "        image = transform(image).unsqueeze(0)\n",
        "    \n",
        "    return image.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHwoXKwlp_R9"
      },
      "source": [
        "# Методы трансформирования изображения\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
        "                                                                            std=(0.229, 0.224, 0.225))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcijlkXKp_SE"
      },
      "source": [
        "# Загружаем оригинал и стиль для картинок, применив нужные методы\n",
        "content = load_image(config.content, transform, maxSize=config.maxSize)\n",
        "style = load_image(config.style, transform, shape=[content.size(2), content.size(3)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNeufG0p_SP"
      },
      "source": [
        "# Создаем место под тензор для конечной картинки, указываем, что дифференцируем \n",
        "target = content.clone().requires_grad_(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-1HH4Nup_SW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "77522c58-18e8-4f73-e83a-080db60ecb7f"
      },
      "source": [
        "model = PretrainedNet().eval() # для использования весов предобученной сетки переводим ее в режим eval\n",
        "optimizer = torch.optim.Adam([target], lr=0.1)\n",
        "contentCriteria = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:11<00:00, 50.9MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0tScbwyp_Sa"
      },
      "source": [
        "for step in range(config.totalStep):\n",
        "    # Для каждого из изображений извлекаем feature map\n",
        "    targetFeatures = model.forward(target)\n",
        "    contentFeatures = model.forward(content) \n",
        "    styleFeatures = model.forward(style)\n",
        "    \n",
        "    styleLoss = 0\n",
        "    contentLoss = 0\n",
        "\n",
        "    for f1, f2, f3 in zip(targetFeatures, contentFeatures, styleFeatures):\n",
        "        # Вычисляем потери для оригинала и конечной картинки\n",
        "        contentLoss += contentCriteria(f1, f2)\n",
        "        #print(contentLoss)\n",
        "\n",
        "        # Меняем форму сверточных feature maps. Приводим к формату (количество каналов, ширина*высота)\n",
        "        _, c, h, w = f1.size() # пропускаем batch\n",
        "        f1 = f1.reshape(c, h*w).to(device) \n",
        "        f3 = f3.reshape(c, h*w).to(device)\n",
        "\n",
        "        # Находим матрицу Грамма для конечной и стиля\n",
        "        f1 = torch.mm(f1, f1.t()) #\n",
        "        f3 = torch.mm(f3, f3.t())\n",
        "\n",
        "        # Потери для стиля и конечной картинки\n",
        "        betta = len(targetFeatures)*len(contentFeatures)**2\n",
        "        styleLoss += (1/4*betta)*contentCriteria(f1,f3) \n",
        "    # Прописываем конечную функцию потерь \n",
        "    loss = styleLoss + betta*contentLoss\n",
        "    #print(betta)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if (step+1) % config.step == 0:\n",
        "        print ('Шаг [{}/{}], Ошибка для оригинала: {:.4f}, Ошибка для стиля: {:.4f}' \n",
        "               .format(step+1, config.totalStep, contentLoss.item(), styleLoss.item()))\n",
        "\n",
        "    if (step+1) % config.sampleStep == 0: # сохраняем нашу картинку\n",
        "        denorm = transforms.Normalize((-2.12, -2.04, -1.80), (4.37, 4.46, 4.44)) # обратное трансформирование\n",
        "        img = target.clone().squeeze() # создаем место под тензор\n",
        "        img = denorm(img).clamp_(0, 1) # оставить значения, попадающие в диапазон между 0,1\n",
        "        torchvision.utils.save_image(img, 'output-{}.png'.format(step+1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}