{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим уменьшенные изображения, уменьшим их еще в 2.5 раза и применим к ним дополнение (augmentation): смещение, контрастность, поворот, размытие.\n",
    "\n",
    "Загрузим данные и разделим их на обучающие и проверочные в соотношении 80/20.\n",
    "\n",
    "Используем Keras для построения нейросети с линейным, сверточными слоями и слоями подвыборки.\n",
    "\n",
    "Обучим модель, используя последовательную загрузку данных. Проведем оценку качества предсказания по коэффициенту сходства.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/clouds/train.csv.gz (54 Мб)\n",
    "* https://video.ittensive.com/machine-learning/clouds/train_images_small.tar.gz (212 Мб)\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/understanding_cloud_organization/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from scipy import ndimage\n",
    "from skimage import transform,util,exposure,io,color\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 210 # 525\n",
    "image_y = 140 # 350\n",
    "image_ch = 1 # 3\n",
    "def mask_rate (a, x, y):\n",
    "    b = a//1400 + 0.0\n",
    "    return np.round(x*(b*x//2100) + y*(a%1400)//1400).astype(\"uint32\")\n",
    "\n",
    "def calc_mask (px, x=image_x, y=image_y):\n",
    "    p = np.array([int(n) for n in px.split(' ')]).reshape(-1,2)\n",
    "    mask = np.zeros(x*y, dtype='uint8')\n",
    "    for i, l in p:\n",
    "        mask[mask_rate(i, x, y) - 1:mask_rate(l+i, x, y)] = 1\n",
    "    return mask.reshape(y,x).transpose()\n",
    "\n",
    "def calc_dice (x):\n",
    "    dice = 0\n",
    "    px = x[\"EncodedPixels\"] \n",
    "    if px != px and x[\"target\"] == 0:\n",
    "        dice = 1\n",
    "    elif px == px and x[\"target\"] == 1:\n",
    "        mask = calc_mask(px).flatten()\n",
    "        target = np.ones(image_x*image_y, dtype='uint8')\n",
    "        dice += 2*np.sum(target[mask==1])/(np.sum(target)+np.sum(mask))\n",
    "    return dice\n",
    "\n",
    "def load_y (df):\n",
    "    return np.array(df[\"EncodedPixels\"].notnull().astype(\"int8\")).reshape(len(df), 1)\n",
    "\n",
    "def load_x (df):\n",
    "    x = [[]]*len(df)\n",
    "    for j, file in enumerate(df[\"Image\"]):\n",
    "        x[j] = io.imread(os.path.join(filesDir, file))\n",
    "    return np.array(x).reshape(len(df), image_y, image_x, image_ch)\n",
    "\n",
    "def load_data (df, batch_size):\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < len(df):\n",
    "            limit = min(batch_end, len(df))\n",
    "            yield (load_x(df[batch_start:limit]),\n",
    "                   load_y(df[batch_start:limit]))\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size\n",
    "\n",
    "def draw_prediction (prediction):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.hist(prediction[0])\n",
    "    ax.set_title(\"Fish\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка и дополнение изображений\n",
    "Преобразуем изображение: уменьшим в 2,5 раза, добавим случайный шум, повернем на 5 градусов по часовой и против часовой стрелки, увеличим контрастность, изменим гамму и добавим размытие по 3 и 7 пикселям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_save (name, data):\n",
    "    io.imsave(os.path.join(filesDir, name),\n",
    "             (data*255).astype(np.uint8))\n",
    "def img_aug (name):\n",
    "    if not os.path.isdir(filesDir):\n",
    "        os.mkdir(filesDir)\n",
    "    img = io.imread(os.path.join(dir_, name))\n",
    "    img = transform.rescale(img, 1 / 2.5)\n",
    "    img_save(name, img)\n",
    "    img_save(\"noised_\" + name, util.random_noise(img))\n",
    "    img_save(\"rotcw_\" + name, transform.rotate(img, -5))\n",
    "    img_save(\"rotccw_\" + name, transform.rotate(img, 5))\n",
    "    v_min, v_max = np.percentile(img, (0.2, 99.8))\n",
    "    img_save(\"cont_\" + name, exposure.rescale_intensity(img,\n",
    "                                in_range=(v_min, v_max)))\n",
    "    img_save(\"gamma_\" + name, exposure.adjust_gamma(img,\n",
    "                                gamma=0.4, gain=0.9))\n",
    "    img_save(\"blurred3_\" + name,\n",
    "            ndimage.uniform_filter(img, size=(3,3,1)))\n",
    "    img_save(\"blurred7_\" + name,\n",
    "            ndimage.uniform_filter(img, size=(7,7,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем все изображения обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"train_images_small\"\n",
    "filesDir = dir_ + \"_tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(dir_):\n",
    "    img_aug(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://video.ittensive.com/machine-learning/clouds/train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        EncodedPixels        Image Label\n",
      "0   264918 937 266318 937 267718 937 269118 937 27...  0011165.jpg  Fish\n",
      "4   233813 878 235213 878 236613 878 238010 881 23...  002be4f.jpg  Fish\n",
      "8   3510 690 4910 690 6310 690 7710 690 9110 690 1...  0031ae9.jpg  Fish\n",
      "12                                                NaN  0035239.jpg  Fish\n",
      "16  2367966 18 2367985 2 2367993 8 2368002 62 2369...  003994e.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "data[\"Image\"] = data[\"Image_Label\"].str.split(\"_\").str[0]\n",
    "data[\"Label\"] = data[\"Image_Label\"].str.split(\"_\").str[1]\n",
    "data.drop(labels=[\"Image_Label\"], axis=1, inplace=True)\n",
    "data_fish = data[data[\"Label\"] == \"Fish\"]\n",
    "print (data_fish.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Разделим всю выборку на 2 части случайным образом: 80% - для обучения модели, 20% - для проверки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels        Image Label\n",
      "16844  373 500 1773 500 3173 500 4573 500 5973 500 73...  c2ad0d8.jpg  Fish\n",
      "18724                                                NaN  d90e620.jpg  Fish\n",
      "6816   423255 412 424655 412 426055 412 427455 412 42...  4e60552.jpg  Fish\n",
      "1064                                                 NaN  0ca6ecd.jpg  Fish\n",
      "9928                                                 NaN  7100409.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data_fish, test_size=0.2)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "del data\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнение обучающих данных\n",
    "Дополним все измененные изображения типами и областями облаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Image                                      EncodedPixels Label\n",
      "0  c2ad0d8.jpg  373 500 1773 500 3173 500 4573 500 5973 500 73...  Fish\n",
      "1  d90e620.jpg                                                NaN  Fish\n",
      "2  4e60552.jpg  423255 412 424655 412 426055 412 427455 412 42...  Fish\n",
      "3  0ca6ecd.jpg                                                NaN  Fish\n",
      "4  7100409.jpg                                                NaN  Fish\n"
     ]
    }
   ],
   "source": [
    "train.set_index(\"Image\", inplace=True)\n",
    "fileList = os.listdir(filesDir)\n",
    "for file in fileList:\n",
    "    img = file.split(\"_\")\n",
    "    if (file not in train.index.values and len(img) > 1 and\n",
    "       img[1] in train.index.values):\n",
    "        train.loc[file] = [train.loc[img[1]][\"EncodedPixels\"], \"Fish\"]\n",
    "train.reset_index(inplace=True)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейросеть\n",
    "Создадим и построим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), input_shape=(image_y, image_x, image_ch),\n",
    "          kernel_initializer=\"glorot_uniform\", strides=(2,2)),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(32, (3,3),\n",
    "          kernel_initializer=\"glorot_uniform\", strides=(2,2)),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Activation(\"softmax\"),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Nadam(lr=0.02),\n",
    "             loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Используем для обучения все изображения, включая измененные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 483s 1s/step - loss: 0.4640\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 252s 712ms/step - loss: 0.4807\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 250s 706ms/step - loss: 0.4722\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 250s 707ms/step - loss: 0.4618\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 251s 708ms/step - loss: 0.4616\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 255s 720ms/step - loss: 0.4633\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4607\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 248s 702ms/step - loss: 0.4565\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 248s 700ms/step - loss: 0.4642\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 252s 713ms/step - loss: 0.4624\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 246s 694ms/step - loss: 0.4563\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4517\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 246s 694ms/step - loss: 0.4547\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4642\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 254s 716ms/step - loss: 0.4608\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 248s 700ms/step - loss: 0.4796\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 248s 700ms/step - loss: 0.4613\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4565\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4738\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 246s 694ms/step - loss: 0.4765\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4516\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4449\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4522\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4578\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4582\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4584\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4704\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 247s 696ms/step - loss: 0.4625\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4597\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4632\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4500\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4452\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 246s 694ms/step - loss: 0.4435\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4484\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 246s 694ms/step - loss: 0.4413\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4396\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 247s 696ms/step - loss: 0.4403\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4502\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 248s 699ms/step - loss: 0.4413\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4393\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4373\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4360\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4360\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 251s 709ms/step - loss: 0.4401\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 268s 758ms/step - loss: 0.4362\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 252s 713ms/step - loss: 0.4408\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4428\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4455\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4647\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4517\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4506\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 246s 694ms/step - loss: 0.4544\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4485\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4472\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 248s 701ms/step - loss: 0.4502\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4547\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 273s 770ms/step - loss: 0.4528\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 263s 743ms/step - loss: 0.4624\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 268s 757ms/step - loss: 0.4495\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4501\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4467\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4475\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4467\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 247s 696ms/step - loss: 0.4446\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4457\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4472\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4451\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4451\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4412\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4409\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4389\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4409\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4497\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4429\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4460\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4422\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 247s 699ms/step - loss: 0.4419\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 246s 696ms/step - loss: 0.4436\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4555\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4472\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 263s 743ms/step - loss: 0.4445\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 269s 760ms/step - loss: 0.4515\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 276s 781ms/step - loss: 0.4478\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 248s 702ms/step - loss: 0.4484\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4483\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4477\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4443\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4448\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 248s 700ms/step - loss: 0.4421\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4407\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4391\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 247s 698ms/step - loss: 0.4407\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 247s 697ms/step - loss: 0.4390\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 248s 699ms/step - loss: 0.4445\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 245s 693ms/step - loss: 0.4417\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4435\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 247s 696ms/step - loss: 0.4418\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 245s 693ms/step - loss: 0.4387\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 246s 695ms/step - loss: 0.4392\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 245s 693ms/step - loss: 0.4421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e126c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(load_data(train, batch_size),\n",
    "            epochs=100, steps_per_epoch=len(train)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110/1110 [==============================] - 20s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(load_data(test, 1),\n",
    "                            steps=len(test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.transpose(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels  target\n",
      "21880  946430 330 947830 330 949230 330 950630 330 95...       1\n",
      "7960                                                 NaN       1\n",
      "4292   158666 31 158698 6 160066 19 160086 1 160088 1...       1\n",
      "21544  602756 314 604153 317 605526 1 605529 1 605532...       1\n",
      "16888  450101 559 451501 559 452901 559 454301 559 45...       1\n",
      "11092                                                NaN       1\n",
      "548    564 535 1101 2 1104 1 1964 535 2501 1 3364 535...       1\n",
      "11720                                                NaN       1\n",
      "6184                                                 NaN       1\n",
      "16660  791722 278 793122 278 794522 278 795922 278 79...       1\n",
      "8      3510 690 4910 690 6310 690 7710 690 9110 690 1...       1\n",
      "4808   830320 891 831720 891 833120 891 834520 891 83...       1\n",
      "13308                                                NaN       1\n",
      "19936                                                NaN       1\n",
      "12                                                   NaN       1\n",
      "6500   321050 271 321327 2 321331 6 322450 275 322727...       1\n",
      "15924  23809 1367 25209 1367 26609 1367 28009 1367 29...       1\n",
      "18996                                                NaN       1\n",
      "9340   951015 321 952415 321 953815 321 955215 321 95...       1\n",
      "21712  374452 740 375852 740 377252 740 378652 740 38...       1\n",
      "1860   427198 384 428598 384 429998 384 431398 384 43...       1\n",
      "4904   291226 394 292626 394 294026 394 295426 394 29...       1\n",
      "8624                                                 NaN       1\n",
      "10956  997356 504 998756 504 1000156 504 1001556 504 ...       1\n",
      "19768                                                NaN       1\n",
      "2424                                                 NaN       1\n",
      "5876   292601 137 292739 3 292752 1 292759 10 294001 ...       1\n",
      "1052   25949 531 27349 531 28749 531 30149 531 31549 ...       1\n",
      "15812  209465 507 210865 507 212265 507 213665 507 21...       1\n",
      "10652  1410 408 2810 408 4210 408 5610 408 7010 408 8...       1\n",
      "...                                                  ...     ...\n",
      "12208  1401 677 2801 677 4201 677 5601 677 7001 677 8...       1\n",
      "1404   31350 377 32750 377 34150 377 35550 377 36950 ...       1\n",
      "4508   861249 831 862649 831 864049 831 865449 831 86...       1\n",
      "20308  1043050 308 1043359 4 1043364 4 1043376 17 104...       1\n",
      "1896                                                 NaN       1\n",
      "15200                                                NaN       1\n",
      "15796                                                NaN       1\n",
      "11324  1340467 518 1341867 518 1343267 518 1344667 51...       1\n",
      "5804   909227 682 910627 682 912027 682 913427 682 91...       1\n",
      "19976  651552 297 652952 297 654352 297 655752 297 65...       1\n",
      "3904                                                 NaN       1\n",
      "7504   1972693 632 1974093 632 1975493 632 1976893 63...       1\n",
      "8172                                                 NaN       1\n",
      "18604  66392 652 67792 652 68607 531 69192 652 70007 ...       1\n",
      "3548                                                 NaN       1\n",
      "15920  1719808 628 1721208 628 1722608 628 1724008 62...       1\n",
      "11688                                                NaN       1\n",
      "11376  1576017 6 1576025 1 1576027 3 1576034 5 157604...       1\n",
      "19148                                                NaN       1\n",
      "18344  482134 855 483534 855 484934 855 486334 855 48...       1\n",
      "20072                                                NaN       1\n",
      "11616  17149 574 18549 574 19949 574 21349 574 22749 ...       1\n",
      "21648  14888 512 16288 512 17688 512 19088 512 20488 ...       1\n",
      "13320                                                NaN       1\n",
      "5304                                                 NaN       1\n",
      "8988                                                 NaN       1\n",
      "976                                                  NaN       1\n",
      "14324  687978 818 689378 818 690778 818 692178 818 69...       1\n",
      "628    350159 748 351559 748 352959 748 354359 748 35...       1\n",
      "20428                                                NaN       1\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test[\"target\"] = (prediction[0] >= 1).astype(\"int8\")\n",
    "print(test[test[\"target\"]>0][[\"EncodedPixels\",\"target\"]].head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка по Дайсу\n",
    "Пока будем считать, что при определении типа облака на изображении, оно целиком размещено на фотографии: т.е. область облака - это все изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет облаков - 0.5, MLP - 0.3, CONV3-32x2,POOL2 - 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras, (CONV3-32x2,POOL2): 0.451\n"
     ]
    }
   ],
   "source": [
    "dice = test.apply(calc_dice, axis=1, result_type=\"expand\")\n",
    "print (\"Keras, (CONV3-32x2,POOL2):\", round(dice.mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
