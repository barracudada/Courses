{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные и разделим их на обучающие и проверочные в соотношении 80/20.\n",
    "\n",
    "Используем Keras для построения нейросети с линейным, сверточными слоями и слоями подвыборки. Проверим, как повышают эффективность обучения нормализация данных и отсев.\n",
    "\n",
    "Обучим модель, используя последовательную загрузку данных. Проведем оценку качества предсказания по коэффициенту сходства.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/clouds/train.csv.gz (54 Мб)\n",
    "* https://video.ittensive.com/machine-learning/clouds/train_images_small.tar.gz (212 Мб)\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/understanding_cloud_organization/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 525 # 525\n",
    "image_y = 350 # 350\n",
    "image_ch = 3 # 3\n",
    "def mask_rate (a, x, y):\n",
    "    b = a//1400 + 0.0\n",
    "    return np.round(x*(b*x//2100) + y*(a%1400)//1400).astype(\"uint32\")\n",
    "\n",
    "def calc_mask (px, x=image_x, y=image_y):\n",
    "    p = np.array([int(n) for n in px.split(' ')]).reshape(-1,2)\n",
    "    mask = np.zeros(x*y, dtype='uint8')\n",
    "    for i, l in p:\n",
    "        mask[mask_rate(i, x, y) - 1:mask_rate(l+i, x, y)] = 1\n",
    "    return mask.reshape(y,x).transpose()\n",
    "\n",
    "def calc_dice (x):\n",
    "    dice = 0\n",
    "    px = x[\"EncodedPixels\"] \n",
    "    if px != px and x[\"target\"] == 0:\n",
    "        dice = 1\n",
    "    elif px == px and x[\"target\"] == 1:\n",
    "        mask = calc_mask(px).flatten()\n",
    "        target = np.ones(image_x*image_y, dtype='uint8')\n",
    "        dice += 2*np.sum(target[mask==1])/(np.sum(target)+np.sum(mask))\n",
    "    return dice\n",
    "\n",
    "def load_y (df):\n",
    "    return np.array(df[\"EncodedPixels\"].notnull().astype(\"int8\")).reshape(len(df), 1)\n",
    "\n",
    "def load_x (df):\n",
    "    x = [[]]*len(df)\n",
    "    for j, file in enumerate(df[\"Image\"]):\n",
    "        x[j] = io.imread(os.path.join(filesDir, file))\n",
    "    return np.array(x).reshape(len(df), image_y, image_x, image_ch)\n",
    "\n",
    "def load_data (df, batch_size):\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < len(df):\n",
    "            limit = min(batch_end, len(df))\n",
    "            yield (load_x(df[batch_start:limit]),\n",
    "                   load_y(df[batch_start:limit]))\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size\n",
    "\n",
    "def draw_prediction (prediction):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.hist(prediction[0])\n",
    "    ax.set_title(\"Fish\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://video.ittensive.com/machine-learning/clouds/train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        EncodedPixels        Image Label\n",
      "0   264918 937 266318 937 267718 937 269118 937 27...  0011165.jpg  Fish\n",
      "4   233813 878 235213 878 236613 878 238010 881 23...  002be4f.jpg  Fish\n",
      "8   3510 690 4910 690 6310 690 7710 690 9110 690 1...  0031ae9.jpg  Fish\n",
      "12                                                NaN  0035239.jpg  Fish\n",
      "16  2367966 18 2367985 2 2367993 8 2368002 62 2369...  003994e.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "data[\"Image\"] = data[\"Image_Label\"].str.split(\"_\").str[0]\n",
    "data[\"Label\"] = data[\"Image_Label\"].str.split(\"_\").str[1]\n",
    "data.drop(labels=[\"Image_Label\"], axis=1, inplace=True)\n",
    "data_fish = data[data[\"Label\"] == \"Fish\"]\n",
    "print (data_fish.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Разделим всю выборку на 2 части случайным образом: 80% - для обучения модели, 20% - для проверки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels        Image Label\n",
      "6104                                                 NaN  4669e71.jpg  Fish\n",
      "8476                                                 NaN  60aa201.jpg  Fish\n",
      "6216   332608 448 334008 448 335408 448 336808 448 33...  476f864.jpg  Fish\n",
      "20804  125255 656 126655 656 128055 656 129455 656 13...  eff8789.jpg  Fish\n",
      "4700                                                 NaN  36198e2.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data_fish, test_size=0.2)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "del data\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генератор данных для обучения\n",
    "Данные всех изображений могут не поместиться в оперативную память, поэтому будем обучать нейросеть последовательно, пакетами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesDir = \"train_images_small\"\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейросеть\n",
    "Создадим модель. Архитектура в общем виде:\n",
    "\n",
    "INPUT -> [[CONV -> RELU] * N -> POOL?] * M -> [FC -> RELU] * K -> FC * L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0314 21:49:40.229383  9288 deprecation_wrapper.py:119] From c:\\users\\nikolay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0314 21:49:40.349390  9288 deprecation.py:506] From c:\\users\\nikolay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), input_shape=(image_y, image_x, image_ch),\n",
    "          kernel_initializer='glorot_uniform', strides=(2,2)),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(32, (3,3),\n",
    "           kernel_initializer='glorot_uniform', strides=(2,2)),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Activation(\"softmax\"),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Nadam(lr=0.02),\n",
    "             loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 1357s 15s/step - loss: 0.5035\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 1356s 15s/step - loss: 0.5060\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 1359s 15s/step - loss: 0.5054\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 1267s 14s/step - loss: 0.5129\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 1211s 14s/step - loss: 0.5120\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 1204s 14s/step - loss: 0.5142\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 1207s 14s/step - loss: 0.5341\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 1216s 14s/step - loss: 0.5228\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 1206s 14s/step - loss: 0.5180\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 1213s 14s/step - loss: 0.5178\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 1208s 14s/step - loss: 0.5075\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 1206s 14s/step - loss: 0.5372\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 1200s 14s/step - loss: 0.5348\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 1198s 14s/step - loss: 0.5355\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 1199s 14s/step - loss: 0.5233\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 1231s 14s/step - loss: 0.5181\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 1199s 14s/step - loss: 0.5197\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 1202s 14s/step - loss: 0.5229\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 1228s 14s/step - loss: 0.5336\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 1198s 14s/step - loss: 0.5232\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 1201s 14s/step - loss: 0.5082\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 1203s 14s/step - loss: 0.5109\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 1196s 14s/step - loss: 0.5047\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 1202s 14s/step - loss: 0.5033\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 1205s 14s/step - loss: 0.5044\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 1206s 14s/step - loss: 0.5051\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 1204s 14s/step - loss: 0.5054\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 1204s 14s/step - loss: 0.4989\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 1204s 14s/step - loss: 0.5023\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 1202s 14s/step - loss: 0.5040\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 1203s 14s/step - loss: 0.5070\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 1201s 14s/step - loss: 0.4926\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 1198s 14s/step - loss: 0.4967\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 1244s 14s/step - loss: 0.4966\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 1239s 14s/step - loss: 0.5002\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 1223s 14s/step - loss: 0.4877\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 10088s 115s/step - loss: 0.5281\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 1423s 16s/step - loss: 0.5525\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 5749s 65s/step - loss: 0.5086\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 1317s 15s/step - loss: 0.4960\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 1366s 16s/step - loss: 0.4913\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 1276s 15s/step - loss: 0.4944\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 1330s 15s/step - loss: 0.4992\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 1230s 14s/step - loss: 0.4905\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 1285s 15s/step - loss: 0.4931\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 1842s 21s/step - loss: 0.5003\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4448s 51s/step - loss: 0.4879\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 11950s 136s/step - loss: 0.4976\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 1741s 20s/step - loss: 0.4937\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 1473s 17s/step - loss: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23df7e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(load_data(train, batch_size),\n",
    "            epochs=50, steps_per_epoch=len(train)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110/1110 [==============================] - 148s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(load_data(test, 1),\n",
    "                            steps=len(test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.transpose(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels  target\n",
      "19652  1124605 556 1126005 556 1127405 556 1128805 55...       1\n",
      "15796                                                NaN       1\n",
      "16904  851201 395 851597 2 851609 8 852601 400 853009...       1\n",
      "12196                                                NaN       1\n",
      "21716  96 777 1496 777 2896 777 4296 777 5696 777 709...       1\n",
      "14268  845 447 2245 447 3645 447 5045 447 6445 447 78...       1\n",
      "13092                                                NaN       1\n",
      "18664                                                NaN       1\n"
     ]
    }
   ],
   "source": [
    "test[\"target\"] = (prediction[0] >= 0.95).astype(\"int8\")\n",
    "print (test[test[\"target\"]>0][[\"EncodedPixels\",\"target\"]].head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка по Дайсу\n",
    "Пока будем считать, что при определении типа облака на изображении, оно целиком размещено на фотографии: т.е. область облака - это все изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет облаков - 0.5, MLP - 0.3, CONV3-32x2,POOL2 - 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras, (CONV3-32x2,POOL2): 0.488\n"
     ]
    }
   ],
   "source": [
    "dice = test.apply(calc_dice, axis=1, result_type=\"expand\")\n",
    "print (\"Keras, (CONV3-32x2,POOL2):\", round(dice.mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
