{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Разберем архитектуру Inception для решения задач распознавания изображений. Построим эту нейросеть для анализа исходных изображений.\n",
    "\n",
    "Используя обученную модель, построим предсказания. Проведем оценку качества предсказания по коэффициенту сходства.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/clouds/train.csv.gz (54 Мб)\n",
    "* https://video.ittensive.com/machine-learning/clouds/train_images_small.tar.gz (212 Мб)\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/understanding_cloud_organization/\n",
    "\n",
    "© ITtensive, 2020\n",
    "\n",
    "![](inception.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import optimizers\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesDir = \"train_images_small\"\n",
    "batch_size = 50\n",
    "image_x = 299 # 525\n",
    "image_y = 299 # 350\n",
    "image_ch = 3 # 3\n",
    "def mask_rate (a, x, y):\n",
    "    b = a//1400 + 0.0\n",
    "    return np.round(x*(b*x//2100) + y*(a%1400)//1400).astype(\"uint32\")\n",
    "\n",
    "def calc_mask (px, x=image_x, y=image_y):\n",
    "    p = np.array([int(n) for n in px.split(' ')]).reshape(-1,2)\n",
    "    mask = np.zeros(x*y, dtype='uint8')\n",
    "    for i, l in p:\n",
    "        mask[mask_rate(i, x, y) - 1:mask_rate(l+i, x, y)] = 1\n",
    "    return mask.reshape(y,x).transpose()\n",
    "\n",
    "def calc_dice (x):\n",
    "    dice = 0\n",
    "    px = x[\"EncodedPixels\"] \n",
    "    if px != px and x[\"target\"] == 0:\n",
    "        dice = 1\n",
    "    elif px == px and x[\"target\"] == 1:\n",
    "        mask = calc_mask(px).flatten()\n",
    "        target = np.ones(image_x*image_y, dtype='uint8')\n",
    "        dice += 2*np.sum(target[mask==1])/(np.sum(target)+np.sum(mask))\n",
    "    return dice\n",
    "\n",
    "def load_y (df):\n",
    "    return np.array(df[\"EncodedPixels\"].notnull().astype(\"int8\")).reshape(len(df), 1)\n",
    "\n",
    "def load_x (df):\n",
    "    x = [[]]*len(df)\n",
    "    for j, file in enumerate(df[\"Image\"]):\n",
    "        img = image.load_img(os.path.join(filesDir, file),\n",
    "                     target_size=(image_y, image_x))\n",
    "        img = image.img_to_array(img)\n",
    "        x[j] = np.expand_dims(img, axis=0)\n",
    "    return np.array(x).reshape(len(df), image_y, image_x, image_ch)\n",
    "\n",
    "def load_data (df, batch_size):\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < len(df):\n",
    "            limit = min(batch_end, len(df))\n",
    "            yield (load_x(df[batch_start:limit]),\n",
    "                   load_y(df[batch_start:limit]))\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n",
    "\n",
    "def draw_prediction (prediction):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.hist(prediction[0])\n",
    "    ax.set_title(\"Fish\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://video.ittensive.com/machine-learning/clouds/train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        EncodedPixels        Image Label\n",
      "0   264918 937 266318 937 267718 937 269118 937 27...  0011165.jpg  Fish\n",
      "4   233813 878 235213 878 236613 878 238010 881 23...  002be4f.jpg  Fish\n",
      "8   3510 690 4910 690 6310 690 7710 690 9110 690 1...  0031ae9.jpg  Fish\n",
      "12                                                NaN  0035239.jpg  Fish\n",
      "16  2367966 18 2367985 2 2367993 8 2368002 62 2369...  003994e.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "data[\"Image\"] = data[\"Image_Label\"].str.split(\"_\").str[0]\n",
    "data[\"Label\"] = data[\"Image_Label\"].str.split(\"_\").str[1]\n",
    "data.drop(labels=[\"Image_Label\"], axis=1, inplace=True)\n",
    "data_fish = data[data[\"Label\"] == \"Fish\"]\n",
    "print (data_fish.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Разделим всю выборку на 2 части случайным образом: 80% - для обучения модели, 20% - для проверки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels        Image Label\n",
      "8572                                                 NaN  619232f.jpg  Fish\n",
      "20308  1043050 308 1043359 4 1043364 4 1043376 17 104...  ea17711.jpg  Fish\n",
      "9800                                                 NaN  6ef9413.jpg  Fish\n",
      "17104                                                NaN  c55412b.jpg  Fish\n",
      "1716   11463 733 12863 733 14263 733 15663 733 17063 ...  136f59b.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data_fish, test_size=0.2)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "del data\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception v3\n",
    "Подключим обученную нейросеть (89 Мб) и построим поверх классификатора новые слои. Используем результат работы обученной нейросети как входной слой для обучения последнего слоя, нашего классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0325 12:05:10.745032  2724 deprecation_wrapper.py:119] From c:\\users\\nikolay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0325 12:05:12.887155  2724 deprecation_wrapper.py:119] From c:\\users\\nikolay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inc_model = InceptionV3(weights='imagenet', include_top=False,\n",
    "                       input_shape=(image_y, image_x, image_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4436/4436 [==============================] - 3404s 767ms/step\n"
     ]
    }
   ],
   "source": [
    "inc_model.compile(optimizer=\"sgd\", loss=\"mean_absolute_error\")\n",
    "inc_model_output = inc_model.predict_generator(load_data(train, 1),\n",
    "                        steps=len(train), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Sequential([\n",
    "    Flatten(input_shape=inc_model_output.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Activation(\"softmax\"),\n",
    "    Dense(1)\n",
    "])\n",
    "top_model.compile(optimizer=optimizers.Nadam(lr=0.02),\n",
    "                 loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4436/4436 [==============================] - 86s 19ms/step - loss: 0.4954\n",
      "Epoch 2/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4887\n",
      "Epoch 3/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4679\n",
      "Epoch 4/100\n",
      "4436/4436 [==============================] - 64s 14ms/step - loss: 0.4676\n",
      "Epoch 5/100\n",
      "4436/4436 [==============================] - 74s 17ms/step - loss: 0.4631\n",
      "Epoch 6/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4632\n",
      "Epoch 7/100\n",
      "4436/4436 [==============================] - 69s 16ms/step - loss: 0.4553\n",
      "Epoch 8/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4580\n",
      "Epoch 9/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4508\n",
      "Epoch 10/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4532\n",
      "Epoch 11/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4510\n",
      "Epoch 12/100\n",
      "4436/4436 [==============================] - 64s 14ms/step - loss: 0.4469\n",
      "Epoch 13/100\n",
      "4436/4436 [==============================] - 77s 17ms/step - loss: 0.4459\n",
      "Epoch 14/100\n",
      "4436/4436 [==============================] - 77s 17ms/step - loss: 0.4453\n",
      "Epoch 15/100\n",
      "4436/4436 [==============================] - 95s 21ms/step - loss: 0.4385\n",
      "Epoch 16/100\n",
      "4436/4436 [==============================] - 75s 17ms/step - loss: 0.4423\n",
      "Epoch 17/100\n",
      "4436/4436 [==============================] - 74s 17ms/step - loss: 0.4376\n",
      "Epoch 18/100\n",
      "4436/4436 [==============================] - 78s 18ms/step - loss: 0.4330\n",
      "Epoch 19/100\n",
      "4436/4436 [==============================] - 77s 17ms/step - loss: 0.4372\n",
      "Epoch 20/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4394\n",
      "Epoch 21/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4307\n",
      "Epoch 22/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4292\n",
      "Epoch 23/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4331\n",
      "Epoch 24/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4292\n",
      "Epoch 25/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4278\n",
      "Epoch 26/100\n",
      "4436/4436 [==============================] - 62s 14ms/step - loss: 0.4258\n",
      "Epoch 27/100\n",
      "4436/4436 [==============================] - 64s 14ms/step - loss: 0.4193\n",
      "Epoch 28/100\n",
      "4436/4436 [==============================] - 83s 19ms/step - loss: 0.4392\n",
      "Epoch 29/100\n",
      "4436/4436 [==============================] - 80s 18ms/step - loss: 0.4324\n",
      "Epoch 30/100\n",
      "4436/4436 [==============================] - 89s 20ms/step - loss: 0.4314\n",
      "Epoch 31/100\n",
      "4436/4436 [==============================] - 90s 20ms/step - loss: 0.4237\n",
      "Epoch 32/100\n",
      "4436/4436 [==============================] - 85s 19ms/step - loss: 0.4188\n",
      "Epoch 33/100\n",
      "4436/4436 [==============================] - 75s 17ms/step - loss: 0.4244\n",
      "Epoch 34/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4275\n",
      "Epoch 35/100\n",
      "4436/4436 [==============================] - 61s 14ms/step - loss: 0.4204\n",
      "Epoch 36/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4279\n",
      "Epoch 37/100\n",
      "4436/4436 [==============================] - 61s 14ms/step - loss: 0.4306\n",
      "Epoch 38/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4302\n",
      "Epoch 39/100\n",
      "4436/4436 [==============================] - 67s 15ms/step - loss: 0.4230\n",
      "Epoch 40/100\n",
      "4436/4436 [==============================] - 83s 19ms/step - loss: 0.4308\n",
      "Epoch 41/100\n",
      "4436/4436 [==============================] - 70s 16ms/step - loss: 0.4229\n",
      "Epoch 42/100\n",
      "4436/4436 [==============================] - 71s 16ms/step - loss: 0.4211\n",
      "Epoch 43/100\n",
      "4436/4436 [==============================] - 70s 16ms/step - loss: 0.4280\n",
      "Epoch 44/100\n",
      "4436/4436 [==============================] - 71s 16ms/step - loss: 0.4226\n",
      "Epoch 45/100\n",
      "4436/4436 [==============================] - 70s 16ms/step - loss: 0.4269\n",
      "Epoch 46/100\n",
      "4436/4436 [==============================] - 71s 16ms/step - loss: 0.4157\n",
      "Epoch 47/100\n",
      "4436/4436 [==============================] - 73s 16ms/step - loss: 0.4147\n",
      "Epoch 48/100\n",
      "4436/4436 [==============================] - 72s 16ms/step - loss: 0.4166\n",
      "Epoch 49/100\n",
      "4436/4436 [==============================] - 71s 16ms/step - loss: 0.4236\n",
      "Epoch 50/100\n",
      "4436/4436 [==============================] - 71s 16ms/step - loss: 0.4141\n",
      "Epoch 51/100\n",
      "4436/4436 [==============================] - 68s 15ms/step - loss: 0.4261\n",
      "Epoch 52/100\n",
      "4436/4436 [==============================] - 72s 16ms/step - loss: 0.4295\n",
      "Epoch 53/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4225\n",
      "Epoch 54/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4180\n",
      "Epoch 55/100\n",
      "4436/4436 [==============================] - 75s 17ms/step - loss: 0.4108\n",
      "Epoch 56/100\n",
      "4436/4436 [==============================] - 71s 16ms/step - loss: 0.4132\n",
      "Epoch 57/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4203\n",
      "Epoch 58/100\n",
      "4436/4436 [==============================] - 68s 15ms/step - loss: 0.4174\n",
      "Epoch 59/100\n",
      "4436/4436 [==============================] - 68s 15ms/step - loss: 0.4116\n",
      "Epoch 60/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4196\n",
      "Epoch 61/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4234\n",
      "Epoch 62/100\n",
      "4436/4436 [==============================] - 70s 16ms/step - loss: 0.4190\n",
      "Epoch 63/100\n",
      "4436/4436 [==============================] - 68s 15ms/step - loss: 0.4130\n",
      "Epoch 64/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4179\n",
      "Epoch 65/100\n",
      "4436/4436 [==============================] - 69s 15ms/step - loss: 0.4184\n",
      "Epoch 66/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4138\n",
      "Epoch 67/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4181\n",
      "Epoch 68/100\n",
      "4436/4436 [==============================] - 74s 17ms/step - loss: 0.4047\n",
      "Epoch 69/100\n",
      "4436/4436 [==============================] - 73s 17ms/step - loss: 0.4158\n",
      "Epoch 70/100\n",
      "4436/4436 [==============================] - 69s 16ms/step - loss: 0.4154\n",
      "Epoch 71/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4167\n",
      "Epoch 72/100\n",
      "4436/4436 [==============================] - 70s 16ms/step - loss: 0.4096\n",
      "Epoch 73/100\n",
      "4436/4436 [==============================] - 66s 15ms/step - loss: 0.4090\n",
      "Epoch 74/100\n",
      "4436/4436 [==============================] - 64s 14ms/step - loss: 0.4270\n",
      "Epoch 75/100\n",
      "4436/4436 [==============================] - 69s 15ms/step - loss: 0.4224\n",
      "Epoch 76/100\n",
      "4436/4436 [==============================] - 64s 15ms/step - loss: 0.4195\n",
      "Epoch 77/100\n",
      "4436/4436 [==============================] - 10038s 2s/step - loss: 0.4124\n",
      "Epoch 78/100\n",
      "4436/4436 [==============================] - 83s 19ms/step - loss: 0.4196\n",
      "Epoch 79/100\n",
      "4436/4436 [==============================] - 76s 17ms/step - loss: 0.4129\n",
      "Epoch 80/100\n",
      "4436/4436 [==============================] - 68s 15ms/step - loss: 0.4181\n",
      "Epoch 81/100\n",
      "4436/4436 [==============================] - 67s 15ms/step - loss: 0.4109\n",
      "Epoch 82/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4194\n",
      "Epoch 83/100\n",
      "4436/4436 [==============================] - 74s 17ms/step - loss: 0.4167\n",
      "Epoch 84/100\n",
      "4436/4436 [==============================] - 67s 15ms/step - loss: 0.4229\n",
      "Epoch 85/100\n",
      "4436/4436 [==============================] - 64s 15ms/step - loss: 0.4166\n",
      "Epoch 86/100\n",
      "4436/4436 [==============================] - 65s 15ms/step - loss: 0.4080\n",
      "Epoch 87/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4235\n",
      "Epoch 88/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4277\n",
      "Epoch 89/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4144\n",
      "Epoch 90/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4115\n",
      "Epoch 91/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4078\n",
      "Epoch 92/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4195\n",
      "Epoch 93/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4215\n",
      "Epoch 94/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4147\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4172\n",
      "Epoch 96/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4115\n",
      "Epoch 97/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4110\n",
      "Epoch 98/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4108\n",
      "Epoch 99/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4034\n",
      "Epoch 100/100\n",
      "4436/4436 [==============================] - 63s 14ms/step - loss: 0.4118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x39aaa688>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.fit(inc_model_output, load_y(train), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            655361      mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,458,145\n",
      "Trainable params: 22,161,569\n",
      "Non-trainable params: 296,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inc_model.input,\n",
    "             outputs=top_model(inc_model.output))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110/1110 [==============================] - 752s 678ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(load_data(test, 1),\n",
    "                        steps=len(test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.transpose(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels  target\n",
      "22032  24699 501 26099 501 27499 501 28899 501 30299 ...       1\n",
      "2116   59303 487 60703 487 62103 487 63503 487 64903 ...       1\n",
      "18288  51802 628 53202 628 54602 628 56002 628 57402 ...       1\n",
      "15824                                                NaN       1\n",
      "13144  873 353 2273 353 3673 353 5073 353 6473 353 78...       1\n",
      "19940  20167 462 21567 462 22967 462 24367 462 25767 ...       1\n",
      "14016                                                NaN       1\n",
      "16068                                                NaN       1\n",
      "11036                                                NaN       1\n",
      "8668   7406 982 8806 982 10206 982 11606 982 13006 98...       1\n",
      "19440                                                NaN       1\n",
      "10148                                                NaN       1\n",
      "2716   460433 8 460457 16 461833 8 461857 16 463233 8...       1\n",
      "15888                                                NaN       1\n",
      "9548   17422 221 18822 221 20222 221 21622 221 23022 ...       1\n",
      "19856  451185 480 452585 480 453985 480 455385 480 45...       1\n",
      "12896  45620 3 45638 2 45642 2 45655 1 45658 1 45660 ...       1\n",
      "7376   39489 633 40889 633 42289 633 43689 633 45089 ...       1\n",
      "4180                                                 NaN       1\n",
      "6488                                                 NaN       1\n",
      "8456   34187 503 35587 503 36987 503 38387 503 39787 ...       1\n",
      "568    18950 650 20350 650 21750 650 23150 650 24550 ...       1\n",
      "11540                                                NaN       1\n",
      "9008   476 766 1876 766 3276 766 4676 766 6076 766 74...       1\n",
      "16540  22 781 1422 781 2822 781 4222 781 5622 781 702...       1\n",
      "4832                                                 NaN       1\n",
      "6540                                                 NaN       1\n",
      "3996                                                 NaN       1\n",
      "4552                                                 NaN       1\n",
      "18952                                                NaN       1\n",
      "17148                                                NaN       1\n"
     ]
    }
   ],
   "source": [
    "test[\"target\"] = (prediction[0]>=1.1).astype(\"int8\")\n",
    "print (test[test[\"target\"]>0][[\"EncodedPixels\",\"target\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет точности предсказания\n",
    "Нет облаков - 0.5, MLP - 0.3, CONV/VGG16 - 0.48, AlexNex - 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras, Inception v3: 0.496\n"
     ]
    }
   ],
   "source": [
    "dice = test.apply(calc_dice, axis=1, result_type=\"expand\")\n",
    "print (\"Keras, Inception v3:\", round(dice.mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
